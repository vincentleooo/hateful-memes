{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessor import CorpusToEmbedding\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./preprocessed/train.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"preprocessed/text_object\", 'rb') as f:\n",
    "    text_obj = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_tokens\"] = text_obj.tokens\n",
    "df[\"labels_tokens\"] = text_obj.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>labels_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>['person', 'person']</td>\n",
       "      <td>[19, 45, 730, 34, 45, 1549, 11, 619, 999999, 9...</td>\n",
       "      <td>[361, 361, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "      <td>['person', 'person', 'person', 'tie']</td>\n",
       "      <td>[98, 34, 38, 4840, 5, 650, 177, 584, 13, 34, 6...</td>\n",
       "      <td>[361, 361, 361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>['cat', 'cat', 'bed']</td>\n",
       "      <td>[1629, 8139, 15, 54, 8544, 999999, 999999, 999...</td>\n",
       "      <td>[3511, 3511, 2818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "      <td>['dog', 'dog']</td>\n",
       "      <td>[650, 749, 3, 3409, 1231, 14, 23171, 2992, 231...</td>\n",
       "      <td>[2369, 2369, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "      <td>['person', 'tie', 'tie']</td>\n",
       "      <td>[3409, 650, 7037, 7027, 435739, 134, 60393, 99...</td>\n",
       "      <td>[361, 4540, 4540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>8495</td>\n",
       "      <td>10423</td>\n",
       "      <td>img/10423.png</td>\n",
       "      <td>1</td>\n",
       "      <td>nobody wants to hang auschwitz me</td>\n",
       "      <td>['person', 'tie', 'tie', 'bed', 'bed', 'bed']</td>\n",
       "      <td>[4014, 405, 5, 8974, 448544, 103, 999999, 9999...</td>\n",
       "      <td>[361, 4540, 4540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>8496</td>\n",
       "      <td>98203</td>\n",
       "      <td>img/98203.png</td>\n",
       "      <td>1</td>\n",
       "      <td>when god grants you a child after 20 years of ...</td>\n",
       "      <td>['person', 'person', 'person', 'person', 'pers...</td>\n",
       "      <td>[71, 3730, 2590, 30, 815, 79, 163, 144, 4, 54,...</td>\n",
       "      <td>[361, 361, 361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>8497</td>\n",
       "      <td>36947</td>\n",
       "      <td>img/36947.png</td>\n",
       "      <td>1</td>\n",
       "      <td>gays on social media: equality! body positivit...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>[2635, 15, 687, 3394, 4683, 561, 41234, 650, 6...</td>\n",
       "      <td>[361, 999999, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>8498</td>\n",
       "      <td>16492</td>\n",
       "      <td>img/16492.png</td>\n",
       "      <td>1</td>\n",
       "      <td>having a bad day? you could be a siamese twin ...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>[282, 816, 193, 30, 169, 38, 282629, 8287, 462...</td>\n",
       "      <td>[361, 999999, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>8499</td>\n",
       "      <td>15937</td>\n",
       "      <td>img/15937.png</td>\n",
       "      <td>1</td>\n",
       "      <td>i hate muslims too they take their religion to...</td>\n",
       "      <td>['cat']</td>\n",
       "      <td>[2992, 17268, 213, 70, 226, 45, 1126, 213, 199...</td>\n",
       "      <td>[3511, 999999, 999999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     id            img  label  \\\n",
       "0              0  42953  img/42953.png      0   \n",
       "1              1  23058  img/23058.png      0   \n",
       "2              2  13894  img/13894.png      0   \n",
       "3              3  37408  img/37408.png      0   \n",
       "4              4  82403  img/82403.png      0   \n",
       "...          ...    ...            ...    ...   \n",
       "8495        8495  10423  img/10423.png      1   \n",
       "8496        8496  98203  img/98203.png      1   \n",
       "8497        8497  36947  img/36947.png      1   \n",
       "8498        8498  16492  img/16492.png      1   \n",
       "8499        8499  15937  img/15937.png      1   \n",
       "\n",
       "                                                   text  \\\n",
       "0      its their character not their color that matters   \n",
       "1     don't be afraid to love again everyone is not ...   \n",
       "2                              putting bows on your pet   \n",
       "3     i love everything and everybody! except for sq...   \n",
       "4     everybody loves chocolate chip cookies, even h...   \n",
       "...                                                 ...   \n",
       "8495                  nobody wants to hang auschwitz me   \n",
       "8496  when god grants you a child after 20 years of ...   \n",
       "8497  gays on social media: equality! body positivit...   \n",
       "8498  having a bad day? you could be a siamese twin ...   \n",
       "8499  i hate muslims too they take their religion to...   \n",
       "\n",
       "                                                 labels  \\\n",
       "0                                  ['person', 'person']   \n",
       "1                 ['person', 'person', 'person', 'tie']   \n",
       "2                                 ['cat', 'cat', 'bed']   \n",
       "3                                        ['dog', 'dog']   \n",
       "4                              ['person', 'tie', 'tie']   \n",
       "...                                                 ...   \n",
       "8495      ['person', 'tie', 'tie', 'bed', 'bed', 'bed']   \n",
       "8496  ['person', 'person', 'person', 'person', 'pers...   \n",
       "8497                                         ['person']   \n",
       "8498                                         ['person']   \n",
       "8499                                            ['cat']   \n",
       "\n",
       "                                            text_tokens  \\\n",
       "0     [19, 45, 730, 34, 45, 1549, 11, 619, 999999, 9...   \n",
       "1     [98, 34, 38, 4840, 5, 650, 177, 584, 13, 34, 6...   \n",
       "2     [1629, 8139, 15, 54, 8544, 999999, 999999, 999...   \n",
       "3     [650, 749, 3, 3409, 1231, 14, 23171, 2992, 231...   \n",
       "4     [3409, 650, 7037, 7027, 435739, 134, 60393, 99...   \n",
       "...                                                 ...   \n",
       "8495  [4014, 405, 5, 8974, 448544, 103, 999999, 9999...   \n",
       "8496  [71, 3730, 2590, 30, 815, 79, 163, 144, 4, 54,...   \n",
       "8497  [2635, 15, 687, 3394, 4683, 561, 41234, 650, 6...   \n",
       "8498  [282, 816, 193, 30, 169, 38, 282629, 8287, 462...   \n",
       "8499  [2992, 17268, 213, 70, 226, 45, 1126, 213, 199...   \n",
       "\n",
       "               labels_tokens  \n",
       "0         [361, 361, 999999]  \n",
       "1            [361, 361, 361]  \n",
       "2         [3511, 3511, 2818]  \n",
       "3       [2369, 2369, 999999]  \n",
       "4          [361, 4540, 4540]  \n",
       "...                      ...  \n",
       "8495       [361, 4540, 4540]  \n",
       "8496         [361, 361, 361]  \n",
       "8497   [361, 999999, 999999]  \n",
       "8498   [361, 999999, 999999]  \n",
       "8499  [3511, 999999, 999999]  \n",
       "\n",
       "[8500 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/miniforge3/envs/hateful-memes-classification/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vincent/miniforge3/envs/hateful-memes-classification/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"new_labels\"] = np.where(df.label == 0, 1, 0)\n",
    "df[\"new_id\"] = df.id.astype(str) # for lexsorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"new_labels\", \"new_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = torch.utils.data.TensorDataset(torch.tensor(df.text_tokens), torch.tensor(df.new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.utils.data.TensorDataset(torch.tensor(df.labels_tokens), torch.tensor(df.new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "images = datasets.ImageFolder(\"./preprocessed/img\", transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "random_sampler = RandomSampler(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loader = torch.utils.data.DataLoader(\n",
    "    images, batch_size=8, sampler=random_sampler\n",
    ")\n",
    "text_loader = torch.utils.data.DataLoader(texts, batch_size=8, sampler=random_sampler)\n",
    "\n",
    "labels_loader = torch.utils.data.DataLoader(labels, batch_size=8, sampler=random_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        drp = 0.1\n",
    "        n_classes = 2\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(text_obj.weights))\n",
    "        self.embedding.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(300, 30, bidirectional=False, batch_first=True)\n",
    "        self.text_linear = nn.Sequential(\n",
    "            nn.Linear(30, 15),\n",
    "            nn.Linear(15, n_classes)\n",
    "        )\n",
    "\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(drp),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(drp),\n",
    "            # # Layer 3\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0),\n",
    "            # # Out: 62, 29\n",
    "            # nn.BatchNorm2d(32),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
    "            # # Out: 30, 14\n",
    "            # nn.Dropout(drp),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(224 * 224 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.unsqueeze(x, dim=1)\n",
    "        x = x[1]\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        out = self.text_linear(h_lstm)\n",
    "        # out1 = self.cnn_layer1(x)\n",
    "        # out2 = self.cnn_layer2(x)\n",
    "        # full_out = torch.cat([out1, out2], dim=1)\n",
    "        # full_out = full_out.view(full_out.size(0), -1)\n",
    "        # x = torch.flatten(out1, start_dim=1)\n",
    "        # x = self.dropout(self.relu(self.fc1(x)))\n",
    "        # x = self.dropout(self.relu(self.fc2(x)))\n",
    "        # x = self.dropout(self.relu(self.fc3(x)))\n",
    "        # x = self.dropout(self.relu(self.fc4(x)))\n",
    "        # x = self.dropout(self.relu(self.fc5(x)))\n",
    "        # out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, weights) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.drp = 0.1\n",
    "        self.n_classes = 2\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(self.drp)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights))\n",
    "\n",
    "        # Text LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            300, 30, bidirectional=False, batch_first=True, num_layers=3, dropout=self.drp\n",
    "        )\n",
    "\n",
    "        # LSTM linear\n",
    "        self.lstm_linear = nn.Sequential(\n",
    "            nn.Linear(900, 450),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(450, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Text CNN\n",
    "        self.text_cnn = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(self.drp),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(self.drp),\n",
    "            # Layer 3\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=(1, 10), padding=(1, 0)),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(self.drp),\n",
    "        )\n",
    "\n",
    "        # Image CNN\n",
    "        self.image_cnn = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(self.drp),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=0),\n",
    "            nn.Dropout(self.drp),\n",
    "            # Layer 3\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=5, stride=1, padding=0),\n",
    "            nn.Dropout(self.drp),\n",
    "        )\n",
    "\n",
    "        # Image + Text CNN\n",
    "        self.combined_cnn = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(self.drp),\n",
    "        )\n",
    "\n",
    "        # Labels linear\n",
    "        self.labels_linear = nn.Sequential(\n",
    "            nn.Linear(900, 450),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(450, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # All linear\n",
    "\n",
    "        self.all_linear = nn.Sequential(\n",
    "            nn.Linear(3100, 1200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1200, 600),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(150, 75),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(75, 2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        img, text, labels = x\n",
    "\n",
    "        # Process image\n",
    "        cnn_img = self.image_cnn(img)\n",
    "\n",
    "        # Process text\n",
    "        text_emb = self.embedding(text)\n",
    "        lstm, _ = self.lstm(text_emb)\n",
    "        lstm_single = lstm.reshape(lstm.shape[0], -1)\n",
    "        lstm_out = self.lstm_linear(lstm_single)\n",
    "        text_emb_cnn = torch.unsqueeze(text_emb, 1)\n",
    "        cnn_text = self.text_cnn(text_emb_cnn)\n",
    "\n",
    "        # Add text and image CNN\n",
    "        combined_cnn = cnn_img + cnn_text\n",
    "        combined_cnn = self.combined_cnn(combined_cnn)\n",
    "        combined_linear = combined_cnn.view(combined_cnn.shape[0], -1)\n",
    "\n",
    "        # Process labels\n",
    "        labels_emb = self.embedding(labels)\n",
    "        labels_single = labels_emb.view(labels.shape[0], 900)\n",
    "        labels_out = self.labels_linear(labels_single)\n",
    "\n",
    "        # Process all\n",
    "        combined_all = torch.cat((lstm_out, combined_linear, labels_out), dim=1)\n",
    "        out = self.all_linear(combined_all)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0300, 0.0356],\n",
      "        [0.0288, 0.0259],\n",
      "        [0.0318, 0.0325],\n",
      "        [0.0234, 0.0269],\n",
      "        [0.0274, 0.0250],\n",
      "        [0.0268, 0.0285],\n",
      "        [0.0267, 0.0281],\n",
      "        [0.0142, 0.0274]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Model(text_obj.weights)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# loss_fn = nn.\n",
    "\n",
    "for (i, j, k) in zip(image_loader, text_loader, labels_loader):\n",
    "    image = i[0].to(device)\n",
    "    text = j[0].to(device)\n",
    "    labels = k[0].to(device)\n",
    "    output = model((image, text, labels)) # hacky way to do this?\n",
    "    print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hateful-memes-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8ecd310e19b1cf28ce5d9cc54ea9408428c7e9a0d412886255a574083418416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
