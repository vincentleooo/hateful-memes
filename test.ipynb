{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessor import CorpusToEmbedding\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./preprocessed/train.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"preprocessed/text_object\", 'rb') as f:\n",
    "    text_obj = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_tokens\"] = text_obj.tokens\n",
    "df[\"labels_tokens\"] = text_obj.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>labels_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>['person', 'person']</td>\n",
       "      <td>[19, 45, 730, 34, 45, 1549, 11, 619, 999999, 9...</td>\n",
       "      <td>[361, 361, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "      <td>['person', 'person', 'person', 'tie']</td>\n",
       "      <td>[98, 34, 38, 4840, 5, 650, 177, 584, 13, 34, 6...</td>\n",
       "      <td>[361, 361, 361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>['cat', 'cat', 'bed']</td>\n",
       "      <td>[1629, 8139, 15, 54, 8544, 999999, 999999, 999...</td>\n",
       "      <td>[3511, 3511, 2818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "      <td>['dog', 'dog']</td>\n",
       "      <td>[650, 749, 3, 3409, 1231, 14, 23171, 2992, 231...</td>\n",
       "      <td>[2369, 2369, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "      <td>['person', 'tie', 'tie']</td>\n",
       "      <td>[3409, 650, 7037, 7027, 435739, 134, 60393, 99...</td>\n",
       "      <td>[361, 4540, 4540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>8495</td>\n",
       "      <td>10423</td>\n",
       "      <td>img/10423.png</td>\n",
       "      <td>1</td>\n",
       "      <td>nobody wants to hang auschwitz me</td>\n",
       "      <td>['person', 'tie', 'tie', 'bed', 'bed', 'bed']</td>\n",
       "      <td>[4014, 405, 5, 8974, 448544, 103, 999999, 9999...</td>\n",
       "      <td>[361, 4540, 4540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>8496</td>\n",
       "      <td>98203</td>\n",
       "      <td>img/98203.png</td>\n",
       "      <td>1</td>\n",
       "      <td>when god grants you a child after 20 years of ...</td>\n",
       "      <td>['person', 'person', 'person', 'person', 'pers...</td>\n",
       "      <td>[71, 3730, 2590, 30, 815, 79, 163, 144, 4, 54,...</td>\n",
       "      <td>[361, 361, 361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>8497</td>\n",
       "      <td>36947</td>\n",
       "      <td>img/36947.png</td>\n",
       "      <td>1</td>\n",
       "      <td>gays on social media: equality! body positivit...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>[2635, 15, 687, 3394, 4683, 561, 41234, 650, 6...</td>\n",
       "      <td>[361, 999999, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>8498</td>\n",
       "      <td>16492</td>\n",
       "      <td>img/16492.png</td>\n",
       "      <td>1</td>\n",
       "      <td>having a bad day? you could be a siamese twin ...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>[282, 816, 193, 30, 169, 38, 282629, 8287, 462...</td>\n",
       "      <td>[361, 999999, 999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>8499</td>\n",
       "      <td>15937</td>\n",
       "      <td>img/15937.png</td>\n",
       "      <td>1</td>\n",
       "      <td>i hate muslims too they take their religion to...</td>\n",
       "      <td>['cat']</td>\n",
       "      <td>[2992, 17268, 213, 70, 226, 45, 1126, 213, 199...</td>\n",
       "      <td>[3511, 999999, 999999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     id            img  label  \\\n",
       "0              0  42953  img/42953.png      0   \n",
       "1              1  23058  img/23058.png      0   \n",
       "2              2  13894  img/13894.png      0   \n",
       "3              3  37408  img/37408.png      0   \n",
       "4              4  82403  img/82403.png      0   \n",
       "...          ...    ...            ...    ...   \n",
       "8495        8495  10423  img/10423.png      1   \n",
       "8496        8496  98203  img/98203.png      1   \n",
       "8497        8497  36947  img/36947.png      1   \n",
       "8498        8498  16492  img/16492.png      1   \n",
       "8499        8499  15937  img/15937.png      1   \n",
       "\n",
       "                                                   text  \\\n",
       "0      its their character not their color that matters   \n",
       "1     don't be afraid to love again everyone is not ...   \n",
       "2                              putting bows on your pet   \n",
       "3     i love everything and everybody! except for sq...   \n",
       "4     everybody loves chocolate chip cookies, even h...   \n",
       "...                                                 ...   \n",
       "8495                  nobody wants to hang auschwitz me   \n",
       "8496  when god grants you a child after 20 years of ...   \n",
       "8497  gays on social media: equality! body positivit...   \n",
       "8498  having a bad day? you could be a siamese twin ...   \n",
       "8499  i hate muslims too they take their religion to...   \n",
       "\n",
       "                                                 labels  \\\n",
       "0                                  ['person', 'person']   \n",
       "1                 ['person', 'person', 'person', 'tie']   \n",
       "2                                 ['cat', 'cat', 'bed']   \n",
       "3                                        ['dog', 'dog']   \n",
       "4                              ['person', 'tie', 'tie']   \n",
       "...                                                 ...   \n",
       "8495      ['person', 'tie', 'tie', 'bed', 'bed', 'bed']   \n",
       "8496  ['person', 'person', 'person', 'person', 'pers...   \n",
       "8497                                         ['person']   \n",
       "8498                                         ['person']   \n",
       "8499                                            ['cat']   \n",
       "\n",
       "                                            text_tokens  \\\n",
       "0     [19, 45, 730, 34, 45, 1549, 11, 619, 999999, 9...   \n",
       "1     [98, 34, 38, 4840, 5, 650, 177, 584, 13, 34, 6...   \n",
       "2     [1629, 8139, 15, 54, 8544, 999999, 999999, 999...   \n",
       "3     [650, 749, 3, 3409, 1231, 14, 23171, 2992, 231...   \n",
       "4     [3409, 650, 7037, 7027, 435739, 134, 60393, 99...   \n",
       "...                                                 ...   \n",
       "8495  [4014, 405, 5, 8974, 448544, 103, 999999, 9999...   \n",
       "8496  [71, 3730, 2590, 30, 815, 79, 163, 144, 4, 54,...   \n",
       "8497  [2635, 15, 687, 3394, 4683, 561, 41234, 650, 6...   \n",
       "8498  [282, 816, 193, 30, 169, 38, 282629, 8287, 462...   \n",
       "8499  [2992, 17268, 213, 70, 226, 45, 1126, 213, 199...   \n",
       "\n",
       "               labels_tokens  \n",
       "0         [361, 361, 999999]  \n",
       "1            [361, 361, 361]  \n",
       "2         [3511, 3511, 2818]  \n",
       "3       [2369, 2369, 999999]  \n",
       "4          [361, 4540, 4540]  \n",
       "...                      ...  \n",
       "8495       [361, 4540, 4540]  \n",
       "8496         [361, 361, 361]  \n",
       "8497   [361, 999999, 999999]  \n",
       "8498   [361, 999999, 999999]  \n",
       "8499  [3511, 999999, 999999]  \n",
       "\n",
       "[8500 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"new_labels\"] = np.where(df.label == 0, 1, 0)\n",
    "df[\"new_id\"] = df.id.astype(str) # for lexsorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"new_labels\", \"new_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = torch.utils.data.TensorDataset(torch.tensor(df.text_tokens), torch.tensor(df.new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.utils.data.TensorDataset(torch.tensor(df.labels_tokens), torch.tensor(df.new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "images = datasets.ImageFolder(\"./preprocessed/img\", transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "random_sampler = RandomSampler(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loader = torch.utils.data.DataLoader(\n",
    "    images, batch_size=32, sampler=random_sampler\n",
    ")\n",
    "text_loader = torch.utils.data.DataLoader(texts, batch_size=32, sampler=random_sampler)\n",
    "\n",
    "labels_loader = torch.utils.data.DataLoader(labels, batch_size=32, sampler=random_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        drp = 0.1\n",
    "        n_classes = 2\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(text_obj.weights))\n",
    "        self.embedding.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(300, 30, bidirectional=False, batch_first=True)\n",
    "        self.text_linear = nn.Sequential(\n",
    "            nn.Linear(30, 15),\n",
    "            nn.Linear(15, n_classes)\n",
    "        )\n",
    "\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(drp),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Dropout(drp),\n",
    "            # # Layer 3\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0),\n",
    "            # # Out: 62, 29\n",
    "            # nn.BatchNorm2d(32),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
    "            # # Out: 30, 14\n",
    "            # nn.Dropout(drp),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(224 * 224 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.unsqueeze(x, dim=1)\n",
    "        x = x[1]\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        out = self.text_linear(h_lstm)\n",
    "        # out1 = self.cnn_layer1(x)\n",
    "        # out2 = self.cnn_layer2(x)\n",
    "        # full_out = torch.cat([out1, out2], dim=1)\n",
    "        # full_out = full_out.view(full_out.size(0), -1)\n",
    "        # x = torch.flatten(out1, start_dim=1)\n",
    "        # x = self.dropout(self.relu(self.fc1(x)))\n",
    "        # x = self.dropout(self.relu(self.fc2(x)))\n",
    "        # x = self.dropout(self.relu(self.fc3(x)))\n",
    "        # x = self.dropout(self.relu(self.fc4(x)))\n",
    "        # x = self.dropout(self.relu(self.fc5(x)))\n",
    "        # out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0141,  0.0636],\n",
      "         [-0.0058,  0.0626],\n",
      "         [-0.0065,  0.0760],\n",
      "         ...,\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833]],\n",
      "\n",
      "        [[-0.0206,  0.0794],\n",
      "         [-0.0024,  0.0777],\n",
      "         [ 0.0111,  0.0729],\n",
      "         ...,\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833]],\n",
      "\n",
      "        [[-0.0220,  0.0688],\n",
      "         [-0.0138,  0.0707],\n",
      "         [-0.0052,  0.0754],\n",
      "         ...,\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0032,  0.0778],\n",
      "         [-0.0018,  0.0889],\n",
      "         [ 0.0059,  0.0920],\n",
      "         ...,\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833]],\n",
      "\n",
      "        [[-0.0023,  0.0701],\n",
      "         [ 0.0092,  0.0741],\n",
      "         [ 0.0007,  0.0629],\n",
      "         ...,\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833],\n",
      "         [ 0.0066,  0.0833]],\n",
      "\n",
      "        [[-0.0006,  0.0765],\n",
      "         [-0.0110,  0.0756],\n",
      "         [-0.0039,  0.0716],\n",
      "         ...,\n",
      "         [ 0.0066,  0.0831],\n",
      "         [ 0.0066,  0.0832],\n",
      "         [ 0.0066,  0.0832]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# loss_fn = nn.\n",
    "\n",
    "for (i, j, k) in zip(image_loader, text_loader, labels_loader):\n",
    "    image = i[0].to(device)\n",
    "    text = j[0].to(device)\n",
    "    output = model([image, text]) # hacky way to do this?\n",
    "    print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hateful-memes-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8ecd310e19b1cf28ce5d9cc54ea9408428c7e9a0d412886255a574083418416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
